{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5fdc80",
   "metadata": {},
   "source": [
    "Evan McLaughlin </br>\n",
    "Vladimir Nimchenko </br>\n",
    "\n",
    "Video Presentation: \n",
    "https://youtu.be/2FwcuF66rGU  </br>\n",
    "\n",
    "This project's goal is to:\n",
    "\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can.\n",
    "\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set.\n",
    "\n",
    "Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress.\n",
    "\n",
    "Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "Describe how the performance on the test set compares to the performance on the dev-test set and if the divergence is expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2caaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas\n",
    "from nltk.corpus import names\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194378fd",
   "metadata": {},
   "source": [
    "\n",
    "Our data is a set of names collected by Mark Kantrowitz and Bill Ross in 1994 where the names are separated in files by gender. There are 7944 observations in total with 5001 female names and 2943 males that are sorted alphabetically.\n",
    "\n",
    "The nltk package allows for directly downloading and accessing this dataset which we do below. Note that dataset loading process is largely identical to sample code provided in the nltk book by Steven Bird, Ewan Klein, and Edward Loper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab13319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\Evan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a9fab",
   "metadata": {},
   "source": [
    "\n",
    "After downloading the dataset that consists of two separate files for male and female, we create a combined list of lists which has each name paired with its gender. Since, these are initially sorted alphabetically we used the random package's ability to shuffle lists in place to allow us to split the data randomly. Note that a seed is set here to encourage reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37bc5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "random.seed(1337)\n",
    "random.shuffle(labeled_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b70ac",
   "metadata": {},
   "source": [
    "\n",
    "We split the `labeled_names` list into a training set with 6944 observations, a dev-test set with 500 observations, and a test set with 500 observations. The training set will be used for training the models, the dev-test set will be used for initially testing the trained models while further developing them, and the test set will be used for the final performance test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd834d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = labeled_names[1000:]\n",
    "devtest_names = labeled_names[500:1000]\n",
    "test_names = labeled_names[:500]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9be131",
   "metadata": {},
   "source": [
    "With our dataset split we can now focus on building a model to classify gender from names. We will focus on three different types of classifiers and optimizing these three classifiers to get the best predictive performance out of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308373b",
   "metadata": {},
   "source": [
    "\n",
    "### Classifier 1: Naive Bayes\n",
    "\n",
    "'''\n",
    "We begin the base of our naive Bayes classifier by looking at how the ntlk book tackles it. We have three different ways to extract features from our dataset:\n",
    "\n",
    "1.   A very simple approach that uses the last letter of the name as the singular feature.\n",
    "2.   A complex approach that predicts based on the first letter of the name, the last letter of the name, and two features for every single letter in the alphabet based on if a letter is present in the name and how many of the letter are present.\n",
    "3.   A simple approach that uses the last two letters of the name as features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22deec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features1(word):\n",
    "  return {'last_letter': word[-1]}\n",
    "\n",
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features\n",
    "\n",
    "def gender_features3(word):\n",
    "  return {'suffix1': word[-1:],\n",
    "          'suffix2': word[-2:]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2fe8b0",
   "metadata": {},
   "source": [
    "If we check the accuracy of each of these feature sets trained to a naive Bayes model we see that the more features we have the greater the accuracy. However, the book showcases that our complex featureset actually ends up overfitting the test set. Thus, our starting point for improvement should be adding and modifying features to the suffix based classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b081653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The gender prediction accuracy for our last letter based classifier is 77.2%\n",
      "The gender prediction accuracy for our large featureset classifier is 80.0%\n",
      "The gender prediction accuracy for our suffix based classifier is 78.2%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set1 = [(gender_features1(n), gender) for (n, gender) in train_names]\n",
    "devtest_set1 = [(gender_features1(n), gender) for (n, gender) in devtest_names]\n",
    "\n",
    "classifier1 = nltk.NaiveBayesClassifier.train(train_set1)\n",
    "\n",
    "train_set2 = [(gender_features2(n), gender) for (n, gender) in train_names]\n",
    "devtest_set2 = [(gender_features2(n), gender) for (n, gender) in devtest_names]\n",
    "\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set2)\n",
    "\n",
    "train_set3 = [(gender_features3(n), gender) for (n, gender) in train_names]\n",
    "devtest_set3 = [(gender_features3(n), gender) for (n, gender) in devtest_names]\n",
    "\n",
    "classifier3 = nltk.NaiveBayesClassifier.train(train_set3)\n",
    "\n",
    "print(f\"\"\"\n",
    "The gender prediction accuracy for our last letter based classifier is {nltk.classify.accuracy(classifier1, devtest_set1)*100}%\n",
    "The gender prediction accuracy for our large featureset classifier is {nltk.classify.accuracy(classifier2, devtest_set2)*100}%\n",
    "The gender prediction accuracy for our suffix based classifier is {nltk.classify.accuracy(classifier3, devtest_set3)*100}%\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb8988",
   "metadata": {},
   "source": [
    "#### Building Upon The Base\n",
    "\n",
    "# Here we begin working on improving our existing naive Bayes model.\n",
    "\n",
    "### Classifier 2: Maximum Entropy Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6e55a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gender prediction accuracy for our MaxEnt classifier is 81.8%\n"
     ]
    }
   ],
   "source": [
    "# let's first define a new feature set but add on suffix-based features as well\n",
    "def gender_features4(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    features['suffix1'] = name[-1:]\n",
    "    features['suffix2'] = name[-2:]\n",
    "    return features\n",
    "\n",
    "# preparing the training and dev-test sets with the new feature set and training the MaxEnt classifier\n",
    "train_set4 = [(gender_features4(n), gender) for (n, gender) in train_names]\n",
    "devtest_set4 = [(gender_features4(n), gender) for (n, gender) in devtest_names]\n",
    "maxent_classifier = nltk.MaxentClassifier.train(train_set4, trace=0)\n",
    "\n",
    "# how is the performance? \n",
    "accuracy_maxent = nltk.classify.accuracy(maxent_classifier, devtest_set4)\n",
    "print(f\"The gender prediction accuracy for our MaxEnt classifier is {accuracy_maxent * 100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49937b",
   "metadata": {},
   "source": [
    "Comparing gender classification accuracies across different classifiers showcases the relative advantage of the Maximum Entropy (MaxEnt) model, which achieves an accuracy of 81.8%, besting Naive Bayes classifiers with accuracies ranging from 77.2% to 80.0%. This highlights the effectiveness of the MaxEnt model's flexibility in handling the complex feature sets that we're tasked with assessing. Additionally, the variation in performance among classifiers emphasizes the significance of feature engineering in improving classification accuracy. Overall, these findings underscore the critical role of both model selection and feature engineering in optimizing gender classification accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
